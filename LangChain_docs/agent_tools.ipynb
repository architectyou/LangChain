{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn8Q2/n6e8dPWlT5gpEQ5H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/architectyou/LangChain/blob/main/LangChain_docs/agent_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNpyTZVetcOL",
        "outputId": "ba71d27f-1603-4257-888d-925ea510553c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bUiOxgsxEsK",
        "outputId": "2135d0e0-a312-4c1a-fe5f-582bad030441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchainhub"
      ],
      "metadata": {
        "id": "CWf6YKda13Dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf57_3_rthcH",
        "outputId": "f47bae73-58e5-46cf-c2f8-c89738373c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(first_int : int, second_int : int)->int:\n",
        "  \"\"\"Multiply two integers together.\"\"\"\n",
        "  return first_int * second_int"
      ],
      "metadata": {
        "id": "6ggwNbnNty-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH9ulxPDuK88",
        "outputId": "cfac1d33-b393-4194-a36c-b36874b0506b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiply\n",
            "Multiply two integers together.\n",
            "{'first_int': {'title': 'First Int', 'type': 'integer'}, 'second_int': {'title': 'Second Int', 'type': 'integer'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"first_int\":4, \"second_int\":5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEuxIx8MuM5a",
        "outputId": "a6273d7d-288c-4256-fb8c-b9aaba6a2be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tool / function calling\n",
        "\n",
        "calling api = function calling\n",
        "tool calling을 지원하는 모델들이 정해져있음. 확인해봐야 함\n",
        "\n",
        "https://python.langchain.com/v0.1/docs/integrations/chat/\n",
        "\n",
        "chat openai는 비동기 invoke, 비동기 streaming, (streaming)을 지원하지 않음 -> 참고할것"
      ],
      "metadata": {
        "id": "9J8yKwWevn-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "Md8jicQmubFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model = \"gpt-3.5-turbo-0125\")"
      ],
      "metadata": {
        "id": "9L_xZi9lw3wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bind_tool 사용\n",
        "llm_with_tools = llm.bind_tools([multiply])"
      ],
      "metadata": {
        "id": "8I4yXmd-xCg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg = llm_with_tools.invoke(\"whats 5 times forty two\")\n",
        "msg.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8xBPQmDysx6",
        "outputId": "4a04ff1a-25ed-4b64-95de-f7462f29c43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'multiply',\n",
              "  'args': {'first_int': 5, 'second_int': 42},\n",
              "  'id': 'call_Eo2qJ5m7EHvtLh8H8VMTFVjF'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "invoking tools -> tool 호출하기"
      ],
      "metadata": {
        "id": "tWrgoIOFzSN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "chain = llm_with_tools | (lambda x : x.tool_calls[0][\"args\"]) | multiply\n",
        "chain.invoke(\"What's four times 23?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNl5ZxXny08P",
        "outputId": "4125b78b-73aa-469e-fcb6-26a90fe1176f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델이 tool을 몇개를 사용할 지 고르고 싶게 하고 싶을 때!\n",
        "\n",
        "- agent를 이용하면 모델이 어떤 순서에 툴을 이용할지를 스스로 결정하게 된다.\n",
        "- tool calling agent를 이용하면 가장 관련있는 tool을 알아서 불러와준다.\n",
        "\n",
        "- agent type들 확인하기\n",
        "https://python.langchain.com/v0.1/docs/modules/agents/agent_types/"
      ],
      "metadata": {
        "id": "aDJaTN2vzyTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent"
      ],
      "metadata": {
        "id": "YoUZ2N1Kzp1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain-hub 에서 prompt 가져오기\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "prompt.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0p3_Gd50kkG",
        "outputId": "9b313fd8-a99d-4daf-9f36-428292fca667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m System Message \u001b[0m================================\n",
            "\n",
            "You are a helpful assistant\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chains with multiple tools\n",
        "\n",
        "@tool\n",
        "def add(first_int : int, second_int : int) -> int:\n",
        "  \"Add two integers.\"\n",
        "  return first_int + second_int\n",
        "\n",
        "@tool\n",
        "def exponentiate(base : int, exponent : int) -> int:\n",
        "  \"Exponentiate the base to the exponent power.\"\n",
        "  return base**exponent\n",
        "\n",
        "tools = [multiply, add, exponentiate]"
      ],
      "metadata": {
        "id": "VECvNMvb1xhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_tool_calling_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "7hU7stQm2iD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agent executor 동작\n",
        "agent_executor = AgentExecutor(agent=agent, tools = tools, verbose = True)"
      ],
      "metadata": {
        "id": "lIbROLjh2mkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\" : \"Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVPt5pc920RK",
        "outputId": "66b012e8-07b1-49c9-9f97-7d11d8ad11ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'base': 3, 'exponent': 5}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'first_int': 12, 'second_int': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `multiply` with `{'first_int': 243, 'second_int': 15}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m3645\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'base': 3645, 'exponent': 2}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m13286025\u001b[0m\u001b[32;1m\u001b[1;3mThe result of taking 3 to the fifth power and multiplying that by the sum of twelve and three, then squaring the whole result is 13,286,025.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result',\n",
              " 'output': 'The result of taking 3 to the fifth power and multiplying that by the sum of twelve and three, then squaring the whole result is 13,286,025.'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원하는 format으로 받고 싶기 때문에 prompt 를 새로 만들어준다.\n",
        "\n",
        "(arguments of tools)\n",
        "- json blob\n",
        "- render : ~하게 하다, 되게 하다"
      ],
      "metadata": {
        "id": "0HnGNHxg3ilY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.render import render_text_description\n",
        "\n",
        "rendered_tools = render_text_description([multiply])\n",
        "rendered_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Wx4oONzL3BXV",
        "outputId": "52de809e-55b5-4112-a487-32d2a05a3962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'multiply(first_int: int, second_int: int) -> int - Multiply two integers together.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool :\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments'\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
        ")"
      ],
      "metadata": {
        "id": "9pwxJtr84Ddr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJjINEtQ43i9",
        "outputId": "b544c609-a42a-4678-bf05-4259718bd8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool : \\n\\nmultiply(first_int: int, second_int: int) -> int - Multiply two integers together.\\n\\nGiven the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments'\\n\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output parser\n",
        "\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature = 0)\n",
        "chain = prompt | model | JsonOutputParser()\n",
        "chain.invoke({\"input\" : \"What's thirteen times 4\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiRPqhCi5Cex",
        "outputId": "1381d4f7-cf77-4e5b-e553-d7c5e83d2d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'multiply', 'arguments': {'first_int': 13, 'second_int': 4}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# invoking the tool\n",
        "\n",
        "from operator import itemgetter\n",
        "# tool의 arguments들을 가져와서 arguments들을 이용하고 싶을 때\n",
        "# json output parser를 이용해서 값을 parsing 하고 그 값을 통해 연산을 수행하고 싶을 때\n",
        "chain = prompt | model | JsonOutputParser() | itemgetter(\"arguments\") | multiply\n",
        "chain.invoke({\"input\" : \"what's thirteen times 4\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raFE-e_U5sj8",
        "outputId": "9d61e56d-6a7a-4d60-98bb-b7e4a2f4a95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mutliple tools로 부터 고르게 하고 싶을 때"
      ],
      "metadata": {
        "id": "110I456w9ZOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tool_chain(model_output):\n",
        "  tool_map = {tool.name : tool for tool in tools}\n",
        "  chosen_tool = tool_map[model_output[\"name\"]]\n",
        "  return itemgetter(\"arguments\") | chosen_tool"
      ],
      "metadata": {
        "id": "-xmoY4I586Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rendered_tools = render_text_description(tools)\n",
        "system_prompt = f\"\"\"\n",
        "You are an assistant that has access to the following set of tools.\n",
        "Here are the names and descriptions for each tool :\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user input, return the name and input of the tool to use.\n",
        "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\" , system_prompt), (\"user\", \"{input}\")]\n",
        ")\n",
        "\n",
        "chain = prompt | model | JsonOutputParser() | tool_chain\n",
        "chain.invoke({\"input\" : \"what's 3 plus 1132\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-W1QZgb9kWr",
        "outputId": "443d71b5-82d1-477b-e8be-a6d5e8c66375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1135"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RunnablePassthrough -> 이용해서 arguments 확인하기\n",
        "\n",
        "어떤 모델을 사용했는지도 출력해줌"
      ],
      "metadata": {
        "id": "xt8whV4Y_bq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output = tool_chain)\n",
        ")\n",
        "chain.invoke({\"input\" : \"What's 3 plus 1132\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p37h8Ke-IbA",
        "outputId": "50e39c4f-a064-4752-827c-b0472ded0dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'add',\n",
              " 'arguments': {'first_int': 3, 'second_int': 1132},\n",
              " 'output': 1135}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\" : \"what's 5 times 4\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXYlqHp8_-W4",
        "outputId": "930d0efa-5545-4ec3-8945-722c67aad0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'multiply',\n",
              " 'arguments': {'first_int': 5, 'second_int': 4},\n",
              " 'output': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function calling 중간에 인간이 개입하기"
      ],
      "metadata": {
        "id": "qZgUApvZAvyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from typing import Dict, List\n",
        "\n",
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.runnables import Runnable, RunnablePassthrough\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def count_emails(last_n_days : int) -> int:\n",
        "  \"\"\"Multiply two integers together.\"\"\"\n",
        "  return last_n_days * 2\n",
        "\n",
        "@tool\n",
        "def send_email(message : str, recipient : str) -> str:\n",
        "  \"Add two integers.\"\n",
        "  return f\"Successfully sent email to {recipient}.\"\n",
        "\n",
        "tools = [count_emails, send_email]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def call_tools(msg : AIMessage) -> List[Dict]:\n",
        "  \"\"\"Simple sequential tool calling helper.\"\"\"\n",
        "  tool_map = {tool.name : tool for tool in tools}\n",
        "  tool_calls = msg.tool_calls.copy()\n",
        "  for tool_call in tool_calls:\n",
        "    tool_call[\"output\"] = tool_map[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
        "  return tool_calls\n",
        "\n",
        "chain = llm_with_tools | call_tools\n",
        "chain.invoke(\"how many emails did i get in the last 5 days?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW3c1dDWAQSo",
        "outputId": "bb112e59-f3c6-4470-bb40-ede03f97b444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'count_emails',\n",
              "  'args': {'last_n_days': 5},\n",
              "  'id': 'call_SOyl3MEE9im8ZFxZ7zJln4S3',\n",
              "  'output': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def human_approval(msg : AIMessage) -> Runnable :\n",
        "  tool_strs = \"\\n\\n\".join(\n",
        "      json.dumps(tool_call, indent = 2) for tool_call in msg.tool_calls\n",
        "  )\n",
        "  input_msg = (\n",
        "      f\"Do you approve of the following tool invocations\\n\\n{tool_strs}\\n\\n\"\n",
        "      \"Anything except 'Y'/'Yes' (case-insensitive) will be treated as a no.\"\n",
        "  )\n",
        "  resp = input(input_msg)\n",
        "  if resp.lower() not in (\"yes\", \"y\"):\n",
        "    raise ValueError(f\"Tool invocations not approved : \\n\\n {tool_strs}\")\n",
        "  return msg"
      ],
      "metadata": {
        "id": "dje040E7CPwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = llm_with_tools | human_approval | call_tools\n",
        "chain.invoke(\"how many emails did i get in the last 5 days?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg714QjbEHDp",
        "outputId": "b3016c6e-6b49-450f-da2a-9fd630426dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you approve of the following tool invocations\n",
            "\n",
            "{\n",
            "  \"name\": \"count_emails\",\n",
            "  \"args\": {\n",
            "    \"last_n_days\": 5\n",
            "  },\n",
            "  \"id\": \"call_uQkbMuIR4qzLnxnXjjTdFzFE\"\n",
            "}\n",
            "\n",
            "Anything except 'Y'/'Yes' (case-insensitive) will be treated as a no.y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'count_emails',\n",
              "  'args': {'last_n_days': 5},\n",
              "  'id': 'call_uQkbMuIR4qzLnxnXjjTdFzFE',\n",
              "  'output': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"Send sally@gmail.com an email saying 'What's up homie'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8cAzmlsEPwu",
        "outputId": "88a24287-04cb-4208-c22e-1c079722be79"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you approve of the following tool invocations\n",
            "\n",
            "{\n",
            "  \"name\": \"send_email\",\n",
            "  \"args\": {\n",
            "    \"message\": \"What's up homie\",\n",
            "    \"recipient\": \"sally@gmail.com\"\n",
            "  },\n",
            "  \"id\": \"call_3MzZmKgtW5oJ9k73njHHcEEU\"\n",
            "}\n",
            "\n",
            "Anything except 'Y'/'Yes' (case-insensitive) will be treated as a no.y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'send_email',\n",
              "  'args': {'message': \"What's up homie\", 'recipient': 'sally@gmail.com'},\n",
              "  'id': 'call_3MzZmKgtW5oJ9k73njHHcEEU',\n",
              "  'output': 'Successfully sent email to sally@gmail.com.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_qilsypEbhQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}